{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Steam Reviews Dataset EDA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Setup and Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from wordcloud import WordCloud\n",
    "import re\n",
    "from collections import Counter\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import warnings\n",
    "\n",
    "# Configure visualization settings\n",
    "plt.style.use('ggplot')\n",
    "sns.set(style=\"whitegrid\")\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Display settings\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (12, 8)\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', 100)\n",
    "pd.set_option('display.float_format', '{:.2f}'.format)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n",
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\user\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    }
   ],
   "source": [
    "# Download NLTK resources\n",
    "try:\n",
    "    nltk.data.find('tokenizers/punkt')\n",
    "    nltk.data.find('corpora/stopwords')\n",
    "except LookupError:\n",
    "    nltk.download('punkt')\n",
    "    nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>&lt;!DOCTYPE html&gt;&lt;html&gt;&lt;head&gt;&lt;title&gt;Google Drive - Virus scan warning&lt;/title&gt;&lt;meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/&gt;&lt;style nonce=\"3WSUK1_wicqFP-RtMwOPbg\"&gt;.goog-link-button{position:relative;color:#15c;text-decoration:underline;cursor:pointer}.goog-link-button-disabled{color:#ccc;text-decoration:none;cursor:default}body{color:#222;font:normal 13px/1.4 arial</th>\n",
       "      <th>sans-serif;margin:0}.grecaptcha-badge{visibility:hidden}.uc-main{padding-top:50px;text-align:center}#uc-dl-icon{display:inline-block;margin-top:16px;padding-right:1em;vertical-align:top}#uc-text{display:inline-block;max-width:68ex;text-align:left}.uc-error-caption</th>\n",
       "      <th>.uc-warning-caption{color:#222;font-size:16px}#uc-download-link{text-decoration:none}.uc-name-size a{color:#15c;text-decoration:none}.uc-name-size a:visited{color:#61c;text-decoration:none}.uc-name-size a:active{color:#d14836;text-decoration:none}.uc-footer{color:#777;font-size:11px;padding-bottom:5ex;padding-top:5ex;text-align:center}.uc-footer a{color:#15c}.uc-footer a:visited{color:#61c}.uc-footer a:active{color:#d14836}.uc-footer-divider{color:#ccc;width:100%}.goog-inline-block{position:relative;display:-moz-inline-box;display:inline-block}* html .goog-inline-block{display:inline}*:first-child+html .goog-inline-block{display:inline}sentinel{}&lt;/style&gt;&lt;link rel=\"icon\" href=\"//ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png\"/&gt;&lt;/head&gt;&lt;body&gt;&lt;div class=\"uc-main\"&gt;&lt;div id=\"uc-dl-icon\" class=\"image-container\"&gt;&lt;div class=\"drive-sprite-aux-download-file\"&gt;&lt;/div&gt;&lt;/div&gt;&lt;div id=\"uc-text\"&gt;&lt;p class=\"uc-warning-caption\"&gt;Google Drive can't scan this file for viruses.&lt;/p&gt;&lt;p class=\"uc-warning-subcaption\"&gt;&lt;span class=\"uc-name-size\"&gt;&lt;a href=\"/open?id=15yHHDXb7JhYW09IQJ90qUi2SHgJk3QyS\"&gt;dataset.csv&lt;/a&gt; (2.0G)&lt;/span&gt; is too large for Google to scan for viruses. Would you still like to download this file?&lt;/p&gt;&lt;form id=\"download-form\" action=\"https://drive.usercontent.google.com/download\" method=\"get\"&gt;&lt;input type=\"submit\" id=\"uc-download-link\" class=\"goog-inline-block jfk-button jfk-button-action\" value=\"Download anyway\"/&gt;&lt;input type=\"hidden\" name=\"id\" value=\"15yHHDXb7JhYW09IQJ90qUi2SHgJk3QyS\"&gt;&lt;input type=\"hidden\" name=\"export\" value=\"download\"&gt;&lt;input type=\"hidden\" name=\"confirm\" value=\"t\"&gt;&lt;input type=\"hidden\" name=\"uuid\" value=\"3951184f-a93a-457a-8eec-f9ccf3969e0b\"&gt;&lt;/form&gt;&lt;/div&gt;&lt;/div&gt;&lt;div class=\"uc-footer\"&gt;&lt;hr class=\"uc-footer-divider\"&gt;&lt;/div&gt;&lt;/body&gt;&lt;/html&gt;</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [<!DOCTYPE html><html><head><title>Google Drive - Virus scan warning</title><meta http-equiv=\"content-type\" content=\"text/html; charset=utf-8\"/><style nonce=\"3WSUK1_wicqFP-RtMwOPbg\">.goog-link-button{position:relative;color:#15c;text-decoration:underline;cursor:pointer}.goog-link-button-disabled{color:#ccc;text-decoration:none;cursor:default}body{color:#222;font:normal 13px/1.4 arial, sans-serif;margin:0}.grecaptcha-badge{visibility:hidden}.uc-main{padding-top:50px;text-align:center}#uc-dl-icon{display:inline-block;margin-top:16px;padding-right:1em;vertical-align:top}#uc-text{display:inline-block;max-width:68ex;text-align:left}.uc-error-caption, .uc-warning-caption{color:#222;font-size:16px}#uc-download-link{text-decoration:none}.uc-name-size a{color:#15c;text-decoration:none}.uc-name-size a:visited{color:#61c;text-decoration:none}.uc-name-size a:active{color:#d14836;text-decoration:none}.uc-footer{color:#777;font-size:11px;padding-bottom:5ex;padding-top:5ex;text-align:center}.uc-footer a{color:#15c}.uc-footer a:visited{color:#61c}.uc-footer a:active{color:#d14836}.uc-footer-divider{color:#ccc;width:100%}.goog-inline-block{position:relative;display:-moz-inline-box;display:inline-block}* html .goog-inline-block{display:inline}*:first-child+html .goog-inline-block{display:inline}sentinel{}</style><link rel=\"icon\" href=\"//ssl.gstatic.com/docs/doclist/images/drive_2022q3_32dp.png\"/></head><body><div class=\"uc-main\"><div id=\"uc-dl-icon\" class=\"image-container\"><div class=\"drive-sprite-aux-download-file\"></div></div><div id=\"uc-text\"><p class=\"uc-warning-caption\">Google Drive can't scan this file for viruses.</p><p class=\"uc-warning-subcaption\"><span class=\"uc-name-size\"><a href=\"/open?id=15yHHDXb7JhYW09IQJ90qUi2SHgJk3QyS\">dataset.csv</a> (2.0G)</span> is too large for Google to scan for viruses. Would you still like to download this file?</p><form id=\"download-form\" action=\"https://drive.usercontent.google.com/download\" method=\"get\"><input type=\"submit\" id=\"uc-download-link\" class=\"goog-inline-block jfk-button jfk-button-action\" value=\"Download anyway\"/><input type=\"hidden\" name=\"id\" value=\"15yHHDXb7JhYW09IQJ90qUi2SHgJk3QyS\"><input type=\"hidden\" name=\"export\" value=\"download\"><input type=\"hidden\" name=\"confirm\" value=\"t\"><input type=\"hidden\" name=\"uuid\" value=\"3951184f-a93a-457a-8eec-f9ccf3969e0b\"></form></div></div><div class=\"uc-footer\"><hr class=\"uc-footer-divider\"></div></body></html>]\n",
       "Index: []"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# https://drive.google.com/file/d/15yHHDXb7JhYW09IQJ90qUi2SHgJk3QyS/view?usp=sharing\n",
    "file_path = \"https://drive.google.com/uc?export=download&id=15yHHDXb7JhYW09IQJ90qUi2SHgJk3QyS\"\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_path)\n",
    "except Exception as e:\n",
    "    print(f\"Error loading CSV with default settings: {e}\")\n",
    "    # Try with different encoding options\n",
    "    try:\n",
    "        df = pd.read_csv(file_path, encoding='latin1')\n",
    "        print(\"Successfully loaded with latin1 encoding\")\n",
    "    except:\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, encoding='utf-8-sig')\n",
    "            print(\"Successfully loaded with utf-8-sig encoding\")\n",
    "        except Exception as e2:\n",
    "            print(f\"Still encountering issues: {e2}\")\n",
    "            # Try reading just the first few lines to diagnose\n",
    "            import subprocess\n",
    "            print(\"File preview:\")\n",
    "            !head -n 5 {file_path}\n",
    "\n",
    "# Display the first few rows to verify loading\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Initial Data Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape of the dataset\n",
    "print(f\"Dataset shape: {df.shape[0]} rows and {df.shape[1]} columns\")\n",
    "\n",
    "# Display column information\n",
    "print(\"\\nColumn Names:\")\n",
    "print(df.columns.tolist())\n",
    "\n",
    "# Display data types and memory usage\n",
    "print(\"\\nData Types and Memory Usage:\")\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for numeric columns\n",
    "print(\"Descriptive Statistics for Numeric Columns:\")\n",
    "df.describe(include=[np.number]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic statistics for object columns\n",
    "print(\"Descriptive Statistics for Text Columns:\")\n",
    "df.describe(include=['object']).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "missing_values = df.isnull().sum()\n",
    "missing_percentage = (missing_values / len(df)) * 100\n",
    "\n",
    "missing_df = pd.DataFrame({\n",
    "    'Missing Values': missing_values,\n",
    "    'Percentage': missing_percentage\n",
    "})\n",
    "\n",
    "print(\"Missing Values Analysis:\")\n",
    "missing_df[missing_df['Missing Values'] > 0]  # Only show columns with missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for duplicates\n",
    "duplicate_count = df.duplicated().sum()\n",
    "print(f\"Number of duplicate rows: {duplicate_count} ({(duplicate_count/len(df))*100:.2f}% of the dataset)\")\n",
    "\n",
    "# If duplicates exist, show a few examples\n",
    "if duplicate_count > 0:\n",
    "    print(\"\\nExample of duplicate entries:\")\n",
    "    df[df.duplicated(keep='first')].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Game Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count of reviews by game\n",
    "game_counts = df['app_name'].value_counts().reset_index()\n",
    "game_counts.columns = ['app_name', 'review_count']\n",
    "\n",
    "# Display the top games by review count\n",
    "print(\"Top 15 Games by Review Count:\")\n",
    "game_counts.head(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top games by review count\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_games = game_counts.head(10).sort_values('review_count')\n",
    "\n",
    "sns.barplot(data=top_games, y='app_name', x='review_count', palette='viridis')\n",
    "plt.title('Top 10 Games by Number of Reviews', fontsize=16)\n",
    "plt.xlabel('Number of Reviews', fontsize=14)\n",
    "plt.ylabel('Game', fontsize=14)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average review score by game\n",
    "game_avg_scores = df.groupby('app_name')['review_score'].agg(['mean', 'count']).reset_index()\n",
    "game_avg_scores = game_avg_scores.rename(columns={'mean': 'avg_score', 'count': 'review_count'})\n",
    "game_avg_scores = game_avg_scores.sort_values('avg_score', ascending=False)\n",
    "\n",
    "# Filter to games with a minimum number of reviews for statistical significance\n",
    "min_reviews = 10\n",
    "top_rated_games = game_avg_scores[game_avg_scores['review_count'] >= min_reviews].head(15)\n",
    "print(f\"Top 15 Highest-Rated Games (with at least {min_reviews} reviews):\")\n",
    "top_rated_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top-rated games (with a minimum number of reviews)\n",
    "plt.figure(figsize=(12, 8))\n",
    "top_10_rated = top_rated_games.head(10).sort_values('avg_score')\n",
    "\n",
    "colors = sns.color_palette(\"RdYlGn\", 10)\n",
    "ax = sns.barplot(data=top_10_rated, y='app_name', x='avg_score', palette=colors)\n",
    "\n",
    "# Add review count as text\n",
    "for i, (score, count) in enumerate(zip(top_10_rated['avg_score'], top_10_rated['review_count'])):\n",
    "    ax.text(score + 0.01, i, f\"n={count}\", va='center')\n",
    "\n",
    "plt.title(f'Top 10 Highest-Rated Games (with ≥{min_reviews} reviews)', fontsize=16)\n",
    "plt.xlabel('Average Review Score', fontsize=14)\n",
    "plt.ylabel('Game', fontsize=14)\n",
    "plt.xlim(0, 1.1)  # Assuming scores are between 0 and 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lowest rated games\n",
    "lowest_rated_games = game_avg_scores[game_avg_scores['review_count'] >= min_reviews].tail(15).sort_values('avg_score')\n",
    "print(f\"15 Lowest-Rated Games (with at least {min_reviews} reviews):\")\n",
    "lowest_rated_games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize lowest-rated games\n",
    "plt.figure(figsize=(12, 8))\n",
    "bottom_10_rated = lowest_rated_games.head(10).sort_values('avg_score', ascending=False)\n",
    "\n",
    "colors = sns.color_palette(\"RdYlGn_r\", 10)\n",
    "ax = sns.barplot(data=bottom_10_rated, y='app_name', x='avg_score', palette=colors)\n",
    "\n",
    "# Add review count as text\n",
    "for i, (score, count) in enumerate(zip(bottom_10_rated['avg_score'], bottom_10_rated['review_count'])):\n",
    "    ax.text(score + 0.01, i, f\"n={count}\", va='center')\n",
    "\n",
    "plt.title(f'10 Lowest-Rated Games (with ≥{min_reviews} reviews)', fontsize=16)\n",
    "plt.xlabel('Average Review Score', fontsize=14)\n",
    "plt.ylabel('Game', fontsize=14)\n",
    "plt.xlim(0, 1.0)  # Assuming scores are between 0 and 1\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of average review scores across all games\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(game_avg_scores['avg_score'], bins=20, kde=True)\n",
    "plt.axvline(game_avg_scores['avg_score'].mean(), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.text(game_avg_scores['avg_score'].mean() + 0.02, plt.gca().get_ylim()[1] * 0.8, \n",
    "         f'Mean: {game_avg_scores[\"avg_score\"].mean():.2f}', color='red')\n",
    "\n",
    "plt.title('Distribution of Average Review Scores Across Games', fontsize=16)\n",
    "plt.xlabel('Average Review Score', fontsize=14)\n",
    "plt.ylabel('Count of Games', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of review count vs. average score\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=game_avg_scores, x='review_count', y='avg_score', alpha=0.6, size='review_count', \n",
    "                sizes=(20, 200), hue='avg_score', palette='RdYlGn')\n",
    "\n",
    "# Add labels to notable points (high review count or extreme scores)\n",
    "for idx, row in game_avg_scores[game_avg_scores['review_count'] > game_avg_scores['review_count'].quantile(0.95)].iterrows():\n",
    "    plt.annotate(row['app_name'], (row['review_count'], row['avg_score']), \n",
    "                 xytext=(5, 5), textcoords='offset points', fontsize=9)\n",
    "\n",
    "plt.title('Review Count vs. Average Score by Game', fontsize=16)\n",
    "plt.xlabel('Number of Reviews', fontsize=14)\n",
    "plt.ylabel('Average Review Score', fontsize=14)\n",
    "plt.xscale('log')  # Log scale for better visualization if there's high variance\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Review Score Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of review scores\n",
    "score_counts = df['review_score'].value_counts().sort_index().reset_index()\n",
    "score_counts.columns = ['review_score', 'count']\n",
    "score_counts['percentage'] = (score_counts['count'] / len(df)) * 100\n",
    "\n",
    "print(\"Distribution of Review Scores:\")\n",
    "score_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize the distribution of review scores\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=score_counts, x='review_score', y='count', palette='viridis')\n",
    "\n",
    "# Add percentage labels on top of bars\n",
    "for i, row in score_counts.iterrows():\n",
    "    ax.text(i, row['count'], f\"{row['percentage']:.1f}%\", ha='center', va='bottom')\n",
    "\n",
    "plt.title('Distribution of Review Scores', fontsize=16)\n",
    "plt.xlabel('Review Score', fontsize=14)\n",
    "plt.ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Review Votes Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of review votes\n",
    "print(\"Distribution of Review Votes:\")\n",
    "vote_stats = df['review_votes'].describe()\n",
    "vote_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create bins for review votes to better visualize the distribution\n",
    "max_votes_to_display = df['review_votes'].quantile(0.99)  # Ignore extreme outliers\n",
    "df_for_plot = df[df['review_votes'] <= max_votes_to_display]\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df_for_plot['review_votes'], bins=30, kde=False)\n",
    "plt.title(f'Distribution of Review Votes (excluding top 1% outliers)', fontsize=16)\n",
    "plt.xlabel('Number of Votes', fontsize=14)\n",
    "plt.ylabel('Count of Reviews', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Relationship between review score and votes\n",
    "vote_by_score = df.groupby('review_score')['review_votes'].agg(['mean', 'median', 'count']).reset_index()\n",
    "print(\"Average and Median Votes by Review Score:\")\n",
    "vote_by_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize relationship between review score and votes\n",
    "plt.figure(figsize=(10, 6))\n",
    "ax = sns.barplot(data=vote_by_score, x='review_score', y='mean', palette='viridis')\n",
    "\n",
    "# Add review count as text\n",
    "for i, count in enumerate(vote_by_score['count']):\n",
    "    ax.text(i, vote_by_score['mean'].iloc[i] + 0.1, f\"n={count:,}\", ha='center')\n",
    "\n",
    "plt.title('Average Review Votes by Score', fontsize=16)\n",
    "plt.xlabel('Review Score', fontsize=14)\n",
    "plt.ylabel('Average Number of Votes', fontsize=14)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reviews with most votes\n",
    "top_voted_reviews = df.sort_values('review_votes', ascending=False).head(10)\n",
    "print(\"Top 10 Most Voted Reviews:\")\n",
    "top_voted_reviews[['app_name', 'review_score', 'review_votes', 'review_text']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Review Text Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add column for review text length\n",
    "df['review_length'] = df['review_text'].apply(lambda x: len(str(x)))\n",
    "df['review_word_count'] = df['review_text'].apply(lambda x: len(str(x).split()))\n",
    "\n",
    "# Basic statistics on review text length\n",
    "print(\"Review Text Length Statistics:\")\n",
    "length_stats = df[['review_length', 'review_word_count']].describe().T\n",
    "length_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of review lengths\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['review_length'], bins=50, kde=True)\n",
    "plt.axvline(df['review_length'].mean(), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.text(df['review_length'].mean() + 10, plt.gca().get_ylim()[1] * 0.8, \n",
    "         f'Mean: {df[\"review_length\"].mean():.1f}', color='red')\n",
    "\n",
    "plt.title('Distribution of Review Text Length (Characters)', fontsize=16)\n",
    "plt.xlabel('Number of Characters', fontsize=14)\n",
    "plt.ylabel('Count of Reviews', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribution of review word counts\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.histplot(df['review_word_count'], bins=50, kde=True)\n",
    "plt.axvline(df['review_word_count'].mean(), color='red', linestyle='dashed', linewidth=1)\n",
    "plt.text(df['review_word_count'].mean() + 2, plt.gca().get_ylim()[1] * 0.8, \n",
    "         f'Mean: {df[\"review_word_count\"].mean():.1f}', color='red')\n",
    "\n",
    "plt.title('Distribution of Review Word Count', fontsize=16)\n",
    "plt.xlabel('Number of Words', fontsize=14)\n",
    "plt.ylabel('Count of Reviews', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare review length by score\n",
    "plt.figure(figsize=(10, 6))\n",
    "sns.boxplot(data=df, x='review_score', y='review_word_count', palette='viridis')\n",
    "plt.title('Review Word Count by Score', fontsize=16)\n",
    "plt.xlabel('Review Score', fontsize=14)\n",
    "plt.ylabel('Word Count', fontsize=14)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare review length by votes\n",
    "# Create vote bins for better analysis\n",
    "df['vote_bins'] = pd.qcut(\n",
    "    df['review_votes'], \n",
    "    q=[0, 0.25, 0.5, 0.75, 0.9, 0.95, 1.0], \n",
    "    labels=['0-25%', '25-50%', '50-75%', '75-90%', '90-95%', '95-100%']\n",
    ")\n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "sns.boxplot(data=df, x='vote_bins', y='review_word_count', palette='viridis')\n",
    "plt.title('Review Word Count by Vote Percentile', fontsize=16)\n",
    "plt.xlabel('Vote Percentile', fontsize=14)\n",
    "plt.ylabel('Word Count', fontsize=14)\n",
    "plt.grid(True, alpha=0.3, axis='y')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function for text preprocessing\n",
    "def preprocess_text(text):\n",
    "    if not isinstance(text, str):\n",
    "        return []\n",
    "    \n",
    "    # Convert to lowercase and remove non-alphanumeric\n",
    "    text = re.sub(r'[^\\w\\s]', '', text.lower())\n",
    "    \n",
    "    # Tokenize\n",
    "    tokens = word_tokenize(text)\n",
    "    \n",
    "    # Remove stopwords\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    tokens = [word for word in tokens if word not in stop_words and len(word) > 1]\n",
    "    \n",
    "    return tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word frequency analysis for all reviews\n",
    "# Sample a subset if the dataset is large\n",
    "sample_size = min(10000, len(df))\n",
    "sample_df = df.sample(sample_size, random_state=42)\n",
    "\n",
    "# Process the sampled text\n",
    "all_words = []\n",
    "for text in sample_df['review_text']:\n",
    "    all_words.extend(preprocess_text(text))\n",
    "\n",
    "# Count word frequencies\n",
    "word_freq = Counter(all_words)\n",
    "common_words = word_freq.most_common(30)\n",
    "\n",
    "print(\"Most Common Words in Reviews:\")\n",
    "for word, count in common_words:\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize most common words\n",
    "plt.figure(figsize=(14, 8))\n",
    "words, counts = zip(*common_words)\n",
    "sns.barplot(x=list(counts), y=list(words), palette='viridis')\n",
    "plt.title('30 Most Common Words in Reviews', fontsize=16)\n",
    "plt.xlabel('Frequency', fontsize=14)\n",
    "plt.ylabel('Word', fontsize=14)\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word cloud\n",
    "wordcloud = WordCloud(width=800, height=400, background_color='white', max_words=100, \n",
    "                     colormap='viridis', collocations=False).generate_from_frequencies(word_freq)\n",
    "\n",
    "plt.figure(figsize=(16, 8))\n",
    "plt.imshow(wordcloud, interpolation='bilinear')\n",
    "plt.axis('off')\n",
    "plt.title('Word Cloud of Review Text', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate reviews by score and analyze word frequencies\n",
    "positive_reviews = sample_df[sample_df['review_score'] == 1]['review_text']\n",
    "negative_reviews = sample_df[sample_df['review_score'] == 0]['review_text']\n",
    "\n",
    "positive_words = []\n",
    "for text in positive_reviews:\n",
    "    positive_words.extend(preprocess_text(text))\n",
    "    \n",
    "negative_words = []\n",
    "for text in negative_reviews:\n",
    "    negative_words.extend(preprocess_text(text))\n",
    "\n",
    "positive_freq = Counter(positive_words)\n",
    "negative_freq = Counter(negative_words)\n",
    "\n",
    "# Top positive words\n",
    "print(\"Most Common Words in Positive Reviews:\")\n",
    "for word, count in positive_freq.most_common(15):\n",
    "    print(f\"{word}: {count}\")\n",
    "    \n",
    "print(\"\\nMost Common Words in Negative Reviews:\")\n",
    "for word, count in negative_freq.most_common(15):\n",
    "    print(f\"{word}: {count}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compare top words in positive and negative reviews\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Positive reviews\n",
    "pos_words, pos_counts = zip(*positive_freq.most_common(15))\n",
    "sns.barplot(x=list(pos_counts), y=list(pos_words), palette='Greens_r', ax=ax1)\n",
    "ax1.set_title('Top Words in Positive Reviews', fontsize=16)\n",
    "ax1.set_xlabel('Frequency', fontsize=14)\n",
    "ax1.set_ylabel('Word', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Negative reviews\n",
    "neg_words, neg_counts = zip(*negative_freq.most_common(15))\n",
    "sns.barplot(x=list(neg_counts), y=list(neg_words), palette='Reds_r', ax=ax2)\n",
    "ax2.set_title('Top Words in Negative Reviews', fontsize=16)\n",
    "ax2.set_xlabel('Frequency', fontsize=14)\n",
    "ax2.set_ylabel('Word', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate word clouds for positive and negative reviews\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Positive reviews wordcloud\n",
    "positive_cloud = WordCloud(width=800, height=400, background_color='white', max_words=100, \n",
    "                         colormap='Greens', collocations=False).generate_from_frequencies(positive_freq)\n",
    "ax1.imshow(positive_cloud, interpolation='bilinear')\n",
    "ax1.axis('off')\n",
    "ax1.set_title('Word Cloud - Positive Reviews', fontsize=16)\n",
    "\n",
    "# Negative reviews wordcloud\n",
    "negative_cloud = WordCloud(width=800, height=400, background_color='white', max_words=100, \n",
    "                         colormap='Reds', collocations=False).generate_from_frequencies(negative_freq)\n",
    "ax2.imshow(negative_cloud, interpolation='bilinear')\n",
    "ax2.axis('off')\n",
    "ax2.set_title('Word Cloud - Negative Reviews', fontsize=16)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the distinctive words for positive and negative reviews\n",
    "def get_distinctive_words(freq1, freq2, top_n=15):\n",
    "    # Create sets of all words\n",
    "    all_words = set(freq1.keys()) | set(freq2.keys())\n",
    "    \n",
    "    # Calculate the ratio of frequencies\n",
    "    distinctive_words = {}\n",
    "    for word in all_words:\n",
    "        # Get frequencies with a minimum of 1 to avoid division by zero\n",
    "        freq1_count = freq1.get(word, 1)\n",
    "        freq2_count = freq2.get(word, 1)\n",
    "        \n",
    "        # Only consider words that appear at least 5 times in one category\n",
    "        if freq1_count >= 5 or freq2_count >= 5:\n",
    "            # Calculate ratio (normalized by total words in each category)\n",
    "            ratio = (freq1_count / sum(freq1.values())) / (freq2_count / sum(freq2.values()))\n",
    "            distinctive_words[word] = ratio\n",
    "    \n",
    "    # Sort and get top distinctive words\n",
    "    return sorted(distinctive_words.items(), key=lambda x: x[1], reverse=True)[:top_n]\n",
    "\n",
    "# Get distinctive words for positive and negative reviews\n",
    "positive_distinctive = get_distinctive_words(positive_freq, negative_freq)\n",
    "negative_distinctive = get_distinctive_words(negative_freq, positive_freq)\n",
    "\n",
    "print(\"Words More Common in Positive Reviews:\")\n",
    "for word, ratio in positive_distinctive:\n",
    "    print(f\"{word}: {ratio:.2f}x more common\")\n",
    "\n",
    "print(\"\\nWords More Common in Negative Reviews:\")\n",
    "for word, ratio in negative_distinctive:\n",
    "    print(f\"{word}: {ratio:.2f}x more common\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize distinctive words\n",
    "fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(18, 8))\n",
    "\n",
    "# Positive distinctive words\n",
    "pos_dist_words, pos_dist_ratios = zip(*positive_distinctive)\n",
    "sns.barplot(x=list(pos_dist_ratios), y=list(pos_dist_words), palette='Greens_r', ax=ax1)\n",
    "ax1.set_title('Words More Common in Positive Reviews', fontsize=16)\n",
    "ax1.set_xlabel('Frequency Ratio (compared to negative reviews)', fontsize=14)\n",
    "ax1.set_ylabel('Word', fontsize=14)\n",
    "ax1.grid(True, alpha=0.3)\n",
    "\n",
    "# Negative distinctive words\n",
    "neg_dist_words, neg_dist_ratios = zip(*negative_distinctive)\n",
    "sns.barplot(x=list(neg_dist_ratios), y=list(neg_dist_words), palette='Reds_r', ax=ax2)\n",
    "ax2.set_title('Words More Common in Negative Reviews', fontsize=16)\n",
    "ax2.set_xlabel('Frequency Ratio (compared to positive reviews)', fontsize=14)\n",
    "ax2.set_ylabel('Word', fontsize=14)\n",
    "ax2.grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Relationships between Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Correlation between numeric variables\n",
    "numeric_df = df[['review_score', 'review_votes', 'review_length', 'review_word_count']]\n",
    "correlation = numeric_df.corr()\n",
    "\n",
    "print(\"Correlation Between Numeric Variables:\")\n",
    "correlation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize correlation matrix\n",
    "plt.figure(figsize=(10, 8))\n",
    "sns.heatmap(correlation, annot=True, cmap='coolwarm', vmin=-1, vmax=1, center=0, \n",
    "            square=True, linewidths=.5, cbar_kws={\"shrink\": .8})\n",
    "plt.title('Correlation Matrix of Numeric Variables', fontsize=16)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scatter plot of review length vs votes with score as color\n",
    "plt.figure(figsize=(12, 8))\n",
    "sns.scatterplot(data=df.sample(min(5000, len(df)), random_state=42), \n",
    "                x='review_word_count', y='review_votes', \n",
    "                hue='review_score', palette={0: 'red', 1: 'green'}, alpha=0.6)\n",
    "plt.title('Relationship between Review Length and Votes', fontsize=16)\n",
    "plt.xlabel('Review Word Count', fontsize=14)\n",
    "plt.ylabel('Number of Votes', fontsize=14)\n",
    "plt.legend(title='Review Score')\n",
    "plt.grid(True, alpha=0.3)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. Key Insights and Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summary of Findings:\n",
    "\n",
    "1. **Review Score Distribution:**\n",
    "   - The dataset shows [to be filled after analysis] distribution of positive vs. negative reviews\n",
    "   - [Game-specific insights about highest and lowest rated games]\n",
    "\n",
    "2. **Review Votes Patterns:**\n",
    "   - [Insights about which reviews get more votes]\n",
    "   - [Any correlation between review score and votes]\n",
    "\n",
    "3. **Review Text Analysis:**\n",
    "   - [Insights about review length]\n",
    "   - [Common words and themes in positive vs negative reviews]\n",
    "   - [Any interesting patterns in review language]\n",
    "\n",
    "4. **Game-specific Insights:**\n",
    "   - [Insights about most reviewed games]\n",
    "   - [Patterns across different games/genres]\n",
    "\n",
    "5. **Relationships Between Variables:**\n",
    "   - [Key correlations discovered]\n",
    "   - [Any surprising relationships]\n",
    "\n",
    "### Recommendations for Further Analysis:\n",
    "\n",
    "1. **Sentiment Analysis:** Apply more advanced NLP techniques to better understand nuanced sentiments in reviews.\n",
    "2. **Topic Modeling:** Identify common themes and topics within reviews using techniques like LDA.\n",
    "3. **Temporal Analysis:** If timestamp data is available, analyze how reviews change over time.\n",
    "4. **Game Category Analysis:** Group games by genre/category to identify category-specific patterns.\n",
    "5. **Predictive Modeling:** Build models to predict review scores or votes based on text content.\n",
    "\n",
    "This exploratory analysis provides a foundation for understanding user sentiment in Steam reviews, highlighting patterns in how users evaluate games and what aspects tend to influence their opinions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
