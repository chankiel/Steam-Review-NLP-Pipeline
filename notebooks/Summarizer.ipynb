{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ae989cb8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cloning into '/content/Steam-Review-NLP-Pipeline'...\n",
      "remote: Enumerating objects: 132, done.\u001b[K\n",
      "remote: Counting objects: 100% (132/132), done.\u001b[K\n",
      "remote: Compressing objects: 100% (95/95), done.\u001b[K\n",
      "remote: Total 132 (delta 40), reused 111 (delta 22), pack-reused 0 (from 0)\u001b[K\n",
      "Receiving objects: 100% (132/132), 1.58 MiB | 22.53 MiB/s, done.\n",
      "Resolving deltas: 100% (40/40), done.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf /content/Steam-Review-NLP-Pipeline\n",
    "!git clone https://github.com/chankiel/Steam-Review-NLP-Pipeline.git /content/Steam-Review-NLP-Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9f8f913c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading...\n",
      "From: https://drive.google.com/uc?id=1yA3RR861M-rWCvVTZ-i_HhvhRNYn2xpF\n",
      "To: /content/summarizer.csv\n",
      "100%|██████████| 45.9M/45.9M [00:00<00:00, 193MB/s]\n"
     ]
    },
    {
     "data": {
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      },
      "text/plain": [
       "'/content/summarizer.csv'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import gdown\n",
    "# https://drive.google.com/file/d/1yA3RR861M-rWCvVTZ-i_HhvhRNYn2xpF/view?usp=sharing\n",
    "url = \"https://drive.google.com/uc?id=1yA3RR861M-rWCvVTZ-i_HhvhRNYn2xpF\"\n",
    "output = \"/content/summarizer.csv\"\n",
    "\n",
    "gdown.download(url, output, quiet=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4005d4ff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First 5 sys.path entries:\n",
      "/content/Steam-Review-NLP-Pipeline/src\n",
      "/content\n",
      "/env/python\n",
      "/usr/lib/python312.zip\n",
      "/usr/lib/python3.12\n",
      "\n",
      "Does src_root exist? True\n",
      "Contents of src_root: ['summarizer', 'training', 'inference', 'api', 'common', 'preprocess', 'utils']\n"
     ]
    }
   ],
   "source": [
    "import sys, os\n",
    "\n",
    "src_root = \"/content/Steam-Review-NLP-Pipeline/src\"\n",
    "sys.path.insert(0, src_root)   # put it at the front\n",
    "\n",
    "print(\"First 5 sys.path entries:\")\n",
    "print(\"\\n\".join(sys.path[:5]))\n",
    "\n",
    "print(\"\\nDoes src_root exist?\", os.path.exists(src_root))\n",
    "print(\"Contents of src_root:\", os.listdir(src_root))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5c7e64d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Does preprocess dir exist? True\n",
      "Contents of preprocess dir: ['sampling.py', '__init__.py', 'filtering.py', '__pycache__', 'sample_review.py', 'group_summarizer.py', 'cleaning.py']\n"
     ]
    }
   ],
   "source": [
    "preprocess_dir = \"/content/Steam-Review-NLP-Pipeline/src/preprocess\"\n",
    "\n",
    "import os\n",
    "print(\"Does preprocess dir exist?\", os.path.exists(preprocess_dir))\n",
    "if os.path.exists(preprocess_dir):\n",
    "    print(\"Contents of preprocess dir:\", os.listdir(preprocess_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c8bb43d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "torch.cuda.empty_cache()\n",
    "from preprocess.group_summarizer import group_reviews\n",
    "from utils.batching import batch_iter\n",
    "\n",
    "from summarizer.pegasus_summarizer import PegasusSummarizer\n",
    "# from summarizer.textrank_summarizer import TextRankSummarizer\n",
    "# from summarizer.lstm_summarizer import LSTMSummarizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1ff93731",
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_CSV = \"/content/summarizer.csv\"\n",
    "df = pd.read_csv(INPUT_CSV)\n",
    "required_cols = {\"app_id\", \"app_name\", \"review_text\"}\n",
    "missing = required_cols - set(df.columns)\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing columns: {missing}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "40764de4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. tryed playing this game when i boot it up im only getting a black screen\n",
      "\n",
      "2. crappy rip off of TF2 don t play it just joking play the game\n",
      "\n",
      "3. The best part was the seizures on the server I played on 4 5 10 needs more seizures\n",
      "\n",
      "4. my friend keeps annying me with it so i dont really like it its more meant as a joke\n",
      "\n",
      "5. the only thing this game suceeds at for me is giving me a full blown headache from the fps and choppy animation\n",
      "\n",
      "6. This game don t have on TF2 Shotty graphics broken characters and NO HATS! Go back to TF2 while you still have your faith in Valve\n",
      "\n",
      "7. Learn about the history of TF2 or get a nostalgia trip I suck at the game so I can t reccomend it\n",
      "\n",
      "8. I honestly don t think this game is even worth the 5 00 that it is There is such little content to go along with the fact that pretty much nobody plays it anymore There are also some critical balance issues with some aspects of the game that are either horribly underpowred and horribly overpowered One prime example of this is the GRENADES please tell me why every class is allowed to use them The grenade system is just broken in my opinion because of how spammable they are I can see why they devs dropped this in TF2 Now I know I haven t played this game for very long AT ALL But I can already see that it has some major issues that simply make it not worth the 5 it is\n",
      "\n",
      "9. Its an okay game and all but there is A A second better and overall more improved game B A FREE second better and overall more improved game\n",
      "\n",
      "10. I tried to love this game But I COULDN T This game has crazy amount of grenade spam and there is no actual way to learn because all the people are veterans TF2 is WAY more balanced And is actually still being updated Also the price is way too high I might update this if I actually see a different side but for now it s a no\n",
      "\n",
      "11. git gud or get out No but seriously no one really cares if you suck\n",
      "\n",
      "12. Extremely high skill ceiling team FPS The current popular competitive format of 4v4 Capture the Flag i e each team takes turns at attacking and defending has made it easier for one person to shine through strong individual play There have been about 600 maps made for this game while some have been duds there are definitely some true gems around Countless different things you can do in execution especially in offence concs etc making this game feel fresh all the time I wish I had played it more when I were younger\n",
      "\n",
      "13. Downloaded the game when finished it said it downloaded half life It lied 3\n",
      "\n",
      "14. This game really is a clasic It has been around longer then Steam\n",
      "\n",
      "15. I ve played this game for thousands of hours since 2005 It s a very fast paced game if you want it to be There are many different classes which you can learn to adapt to your gaming style The easiest class to start is a sniper The skill is to learn to use any class in any situation The community used to be top notch Nowadays there are less and less people playing TFC needs new blood There are many different maps and modes like CTF CP There are also many fun maps where you f e can climb explore and solve mysteries In short TFC is a simple yet complicated game If you like a challenge pick it up\n",
      "\n",
      "16. Extremely fun great community great challange and people that actually respect new player s What more could you ask for?\n",
      "\n",
      "17. Team Fortress Classic Balanced and fair multiplayer No hats No 5 year old calling people s Is fun with friends and strangers TFC 9 10 good fun with the lads TF2 Hats oh god the hats Unbalanced gameplay due to the fact its pretty much pay to win Destroys friendships Is total Tf2 3 10 would not buy hat again\n",
      "\n",
      "18. I really loved this game back in the day when i was about 10 or 11 Now i am 12 and i had REALLY forgotten how awesome this was but i just decided to play it again and i had a flashback to the good old memories of TFC How did i let this game become worthless to me i should play it more oftenly and you should do the same! I strongly recommend this game\n",
      "\n",
      "19. My TFC Review Aw Yiss Graphics 5 5 10 Pretty decent graphics for an old game Gameplay 7 10 The HEV suit thingy makes the character quite tanky in tfc otherwise great gameplay Hats 0 10 Valve y u dont put hats jk screw those Servers 2 10 The servers are dead and mostly there s 2 6 players in a server based on what I have seen Grenades 7 10 Would spam grenades Overall 8 10 Still good for an old game I wouldn t recommend buying this but It would be cool if you got this gaem D\n",
      "\n",
      "20. 2laggy4me still good game though for the 30 minutes i played 6 10 good enough for me\n",
      "\n"
     ]
    }
   ],
   "source": [
    "grouped = group_reviews(df)\n",
    "grouped = grouped.reset_index(drop=True)\n",
    "\n",
    "len(grouped), grouped.head()\n",
    "\n",
    "target_app_id = 20\n",
    "app_reviews = df[df[\"app_id\"] == target_app_id][\"review_text\"].dropna()\n",
    "\n",
    "for i, review in enumerate(app_reviews, start=1):\n",
    "    print(f\"{i}. {review}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f79a3a10",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_summarizer(model_name: str):\n",
    "    model_name = model_name.lower()\n",
    "    if model_name == \"pegasus\":\n",
    "        return PegasusSummarizer()\n",
    "    # if model_name == \"textrank\":\n",
    "    #     return TextRankSummarizer()\n",
    "    # if model_name == \"lstm\":\n",
    "    #     return LSTMSummarizer()\n",
    "    raise ValueError(f\"Unknown model: {model_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3aab39d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.notebook import tqdm\n",
    "import math\n",
    "\n",
    "def summarize_chunk(\n",
    "    grouped_df,\n",
    "    summarizer,\n",
    "    start_idx: int,\n",
    "    end_idx: int,\n",
    "    batch_size: int,\n",
    "    output_path: str,\n",
    "    desc: str = \"Summarizing chunk\",\n",
    "):\n",
    "    \"\"\"\n",
    "    Summarize a slice of `grouped_df` from row [start_idx:end_idx]\n",
    "    and save a CSV with columns: app_id, app_name, summary_review.\n",
    "\n",
    "    - grouped_df: the full grouped dataframe (with clean_text)\n",
    "    - summarizer: e.g. get_summarizer(\"pegasus\")\n",
    "    - start_idx, end_idx: row range (iloc style)\n",
    "    - batch_size: small for Pegasus (1–2)\n",
    "    - output_path: where to save the CSV\n",
    "    - desc: label for tqdm progress bar\n",
    "    \"\"\"\n",
    "    # take only the chunk we want\n",
    "    chunk = grouped_df.iloc[start_idx:end_idx].copy()\n",
    "    if len(chunk) == 0:\n",
    "        print(f\"No rows in range [{start_idx}, {end_idx}). Skipping.\")\n",
    "        return\n",
    "\n",
    "    print(f\"Chunk rows: {start_idx} to {end_idx-1} (total {len(chunk)})\")\n",
    "    \n",
    "    indices = chunk.index.tolist()\n",
    "    total_batches = math.ceil(len(indices) / batch_size)\n",
    "    summaries = []\n",
    "    batch_num = 0\n",
    "\n",
    "    for idx_batch in tqdm(\n",
    "        batch_iter(indices, batch_size),\n",
    "        total=total_batches,\n",
    "        desc=desc,\n",
    "    ):\n",
    "        batch_num += 1\n",
    "        print(f\"=== Batch {batch_num}/{total_batches} ===\")\n",
    "\n",
    "        texts = chunk.iloc[idx_batch][\"clean_text\"].tolist()\n",
    "        batch_summaries = summarizer.summarize_batch(texts)\n",
    "        summaries.extend(batch_summaries)\n",
    "\n",
    "        # free VRAM between batches (important for Pegasus)\n",
    "        if torch.cuda.is_available():\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "    # build result df for this chunk\n",
    "    result_df = chunk[[\"app_id\", \"app_name\"]].copy()\n",
    "    result_df[\"summary_review\"] = summaries\n",
    "\n",
    "    result_df.to_csv(output_path, index=False)\n",
    "    print(f\"Saved chunk to: {output_path}\")\n",
    "    return result_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b69ea5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total grouped games: 8067\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "# e.g. 1 or 2 for Pegasus (to avoid OOM)\n",
    "BATCH_SIZE_MODEL = 8\n",
    "\n",
    "# Make sure `grouped` already exists (from your previous cells)\n",
    "print(\"Total grouped games:\", len(grouped))\n",
    "\n",
    "os.makedirs(\"/content/Steam-Review-NLP-Pipeline/data/processed\", exist_ok=True)\n",
    "\n",
    "pegasus_summarizer = get_summarizer(\"pegasus\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a93b3c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk rows: 0 to 199 (total 200)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7ecd9e005e4248989950643843d36ccd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Summarizing chunk 1:   0%|          | 0/25 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Batch 1/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 2/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 3/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 4/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 5/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 6/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 7/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 8/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 9/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 10/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 11/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 12/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 13/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 14/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 15/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 16/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 17/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 18/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 19/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 20/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 21/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 22/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 23/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 24/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "=== Batch 25/25 ===\n",
      "[Pegasus] Running generation on 8 items...\n",
      "Saved chunk to: D:\\Projects\\NLP Steam Review\\Steam-Review-NLP-Pipeline\\data\\processed\\summaries_pegasus_1.csv\n"
     ]
    }
   ],
   "source": [
    "chunk_start = 0\n",
    "chunk_end = 200   # up to but not including\n",
    "\n",
    "output_path_1 = \"/content/Steam-Review-NLP-Pipeline/data/processed/summaries_pegasus_1.csv\"\n",
    "\n",
    "df_chunk_1 = summarize_chunk(\n",
    "    grouped_df=grouped,\n",
    "    summarizer=pegasus_summarizer,\n",
    "    start_idx=chunk_start,\n",
    "    end_idx=chunk_end,\n",
    "    batch_size=BATCH_SIZE_MODEL,\n",
    "    output_path=output_path_1,\n",
    "    desc=\"Summarizing chunk 1\",\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c54dc93f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "<module 'posixpath' (frozen)>\n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
